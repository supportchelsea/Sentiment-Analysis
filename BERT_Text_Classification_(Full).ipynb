{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Text Classification (Full).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supportchelsea/Sentimental-Analysis/blob/master/BERT_Text_Classification_(Full).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yF2I-Cs2JPd",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "데이터 파일을 불러와서 pandas DataFrame으로 구성하는 방법을 실습해보겠습니다.\n",
        "\n",
        "우선 학습 데이터를 다운로드하고 압축을 풉니다.\n",
        "\n",
        "데이터 출처: http://www.cs.cornell.edu/~cristian/Politeness.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gc4A1T5E8hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"Stanford_politeness_corpus.zip\"):\n",
        "  !wget http://www.cs.cornell.edu/~cristian/Politeness_files/Stanford_politeness_corpus.zip\n",
        "\n",
        "if not os.path.exists(\"Stanford_politeness_corpus/wikipedia.annotated.csv\"):\n",
        "  !unzip Stanford_politeness_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHwRbG7yFGnA",
        "colab_type": "text"
      },
      "source": [
        "다운로드된 데이터셋은 CSV 파일 형태로 되어 있습니다.\n",
        "\n",
        "파일이 어떻게 구성되어 있는지 살펴볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD_v09epFM_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head Stanford_politeness_corpus/wikipedia.annotated.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FIcfBdlFo1v",
        "colab_type": "text"
      },
      "source": [
        "한 줄이 하나의 데이터를 나타내고, 각 데이터 값들은 쉼표로 구분되어 있는 것을 볼 수 있습니다.\n",
        "\n",
        "또한, 첫 줄은 각 데이터 값들이 어떤 항목을 나타내는지 알려주는 헤더입니다.\n",
        "\n",
        "이런 형식의 데이터 파일은 pandas의 read_csv 함수를 이용하여 쉽게 불러올 수 있습니다.\n",
        "\n",
        "참고: [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfbywkLaGk8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"Stanford_politeness_corpus/wikipedia.annotated.csv\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP8-E2DzG9mE",
        "colab_type": "text"
      },
      "source": [
        "이번엔 다른 형태의 데이터를 다운로드 받아보겠습니다. [GLUE dataset](https://gluebenchmark.com) 중 하나인 Stanford Sentiment Treebank 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqhh3OhwHOts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "download_url = \"https://firebasestorage.googleapis.com/v0/b/mtl-sentence-representations.appspot.com/o/data%2FSST-2.zip?alt=media&token=aabc5f6b-e466-44a2-b9b4-cf6337f84ac8\"\n",
        "\n",
        "if not os.path.exists(\"sst.zip\"):\n",
        "  urllib.request.urlretrieve(download_url, \"sst.zip\")\n",
        "\n",
        "if not os.path.exists(\"SST-2/train.tsv\"):\n",
        "  !unzip -o sst.zip\n",
        "  \n",
        "!head SST-2/train.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goMc41d7ICTl",
        "colab_type": "text"
      },
      "source": [
        "이번에도 한 줄이 하나의 데이터를 나타냅니다. \n",
        "\n",
        "하지만 이번에는 데이터 항목들 간의 구분자가 쉼표가 아닌 탭입니다.\n",
        "\n",
        "pandas.read_csv 함수는 sep 파라미터를 이용하여 구분자를 지정해줄 수 있습니다. 앞선 사용 예에서는 sep이 지정되지 않았는데, 이 때는 쉼표가 기본값으로 사용됩니다.\n",
        "\n",
        "다시 한 번 pandas.read_csv 함수를 이용하여 이 데이터셋을 불러와보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4m5XGPuIXrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"SST-2/train.tsv\", sep='\\t')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3d2cLC5IoZ7",
        "colab_type": "text"
      },
      "source": [
        "파일 파싱 에러(ParseError) 등으로 인해 read_csv 함수를 사용할 수 없는 경우도 있습니다. \n",
        "\n",
        "그런 경우는 우선 python을 이용하여 데이터를 배열 형태로 불러오고, 이로부터 pandas DataFrame을 생성할 수 있습니다.\n",
        "\n",
        "Microsoft Research Paraphrase Corpus(MRPC)를 이용하여 이러한 경우를 실습해보겠습니다.\n",
        "\n",
        "MRPC는 저작권 문제로 인해 마이크로소프트 홈페이지에서 다운로드를 받아야 합니다. 다음 링크에서 데이터를 다운로드 받아주세요.\n",
        "\n",
        "https://www.microsoft.com/en-us/download/details.aspx?id=52398\n",
        "\n",
        "다운로드 완료 후에는 좌측의 파일 업로드 기능을 이용하여 해당 파일을 업로드해주시기 바랍니다.\n",
        "\n",
        "해당 파일은 msi 형태로, 별도의 프로그램을 통해 압축을 풀고 스크립트를 이용해 전처리를 해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_97i0cqwI9AA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"MRPC/msr_paraphrase_train.txt\"):\n",
        "  !apt install cabextract\n",
        "\n",
        "  !cabextract MSRParaphraseCorpus.msi -d MRPC\n",
        "  !cat MRPC/_2DEC3DBE877E4DB192D17C0256E90F1D | tr -d $'\\r' > MRPC/msr_paraphrase_train.txt\n",
        "  !cat MRPC/_D7B391F9EAFF4B1B8BCE8F21B20B1B61 | tr -d $'\\r' > MRPC/msr_paraphrase_test.txt\n",
        "  !rm MRPC/_*\n",
        "  \n",
        "!head MRPC/msr_paraphrase_train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IV_MkGdLFuq",
        "colab_type": "text"
      },
      "source": [
        "다음으로 python으로 파일을 읽고 각 줄을 탭을 기준으로 분리하는 과정을 통해 DataFrame을 생성해보겠습니다.\n",
        "\n",
        "이 경우에는 columns 파라미터를 통해 헤더를 직접 지정해줘야 합니다.\n",
        "\n",
        "참고: [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wa6lxRuLWNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"MRPC/msr_paraphrase_train.txt\", 'r') as fh:\n",
        "  raw_data = [line.strip().split('\\t') for line in fh]\n",
        "  \n",
        "data = pd.DataFrame(raw_data[1:], columns=raw_data[0])\n",
        "  \n",
        "print(data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ1XRuk_HPUR",
        "colab_type": "text"
      },
      "source": [
        "## BERT를 이용한 Text Classification\n",
        "\n",
        "BERT를 이용한 text classification 모델을 만들고 학습시켜보겠습니다.\n",
        "\n",
        "우선 필요한 패키지를 설치해야 합니다. bert-tensorflow 패키지는 구글에서 공개한 BERT의 코드로부터 BERT 사용에 필요한 함수들을 활용할 수 있게 해줍니다.\n",
        "\n",
        "참고: [BERT github](https://github.com/google-research/bert)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adzlJRbDyc3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az_pyElrvT6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "import os\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(bert_model_hub)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                                  tokenization_info[\"do_lower_case\"]])\n",
        "\n",
        "        print(\"Using BERT from %s\" %bert_model_hub)\n",
        "        print(\"with vocab size=%d and do_lower_case=%s.\" %(len(vocab_file), str(do_lower_case)))\n",
        "\n",
        "    return bert.tokenization.FullTokenizer(\n",
        "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                             text_a=x[DATA_COLUMN],\n",
        "                                                                             text_b=None,\n",
        "                                                                             label=x[LABEL_COLUMN]), axis=1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "    bert_module = hub.Module(\n",
        "        bert_model_hub,\n",
        "        trainable=True)\n",
        "    bert_inputs = dict(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(\n",
        "        inputs=bert_inputs,\n",
        "        signature=\"tokens\",\n",
        "        as_dict=True)\n",
        "\n",
        "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "    # Use \"sequence_outputs\" for token-level output.\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "    with tf.variable_scope(\"output_layer\"):\n",
        "        layer_out = tf.layers.dense(\n",
        "            inputs=output_layer,\n",
        "            units=num_labels,\n",
        "            use_bias=False,\n",
        "            kernel_initializer=tf.initializers.variance_scaling()\n",
        "        )\n",
        "        predicted_labels = tf.squeeze(tf.argmax(layer_out, axis=-1, output_type=tf.int32))\n",
        "\n",
        "        if is_predicting:\n",
        "            return predicted_labels, layer_out\n",
        "        else:\n",
        "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                labels=labels,\n",
        "                logits=layer_out\n",
        "            )\n",
        "            loss = tf.reduce_mean(loss)\n",
        "\n",
        "            return loss, predicted_labels, layer_out\n",
        "\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "\n",
        "        # TRAIN and EVAL\n",
        "        if not is_predicting:\n",
        "\n",
        "            (loss, predicted_labels, log_probs) = create_model(\n",
        "                bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            train_op = bert.optimization.create_optimizer(\n",
        "                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "            # Calculate evaluation metrics.\n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                auc = tf.metrics.auc(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                recall = tf.metrics.recall(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                precision = tf.metrics.precision(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_pos = tf.metrics.true_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_neg = tf.metrics.true_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                false_pos = tf.metrics.false_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                false_neg = tf.metrics.false_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"f1_score\": f1_score,\n",
        "                    \"auc\": auc,\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"true_positives\": true_pos,\n",
        "                    \"true_negatives\": true_neg,\n",
        "                    \"false_positives\": false_pos,\n",
        "                    \"false_negatives\": false_neg\n",
        "                }\n",
        "\n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                                  loss=loss,\n",
        "                                                  train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                                  loss=loss,\n",
        "                                                  eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs) = create_model(\n",
        "                bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            predictions = {\n",
        "                'probabilities': log_probs,\n",
        "                'labels': predicted_labels\n",
        "            }\n",
        "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn\n",
        "\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE,\n",
        "                      num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "        bert_model_hub=bert_model_hub,\n",
        "        num_labels=len(label_list),\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n",
        "\n",
        "\n",
        "def run_on_dfs(train, test, data_column, label_column,\n",
        "               max_seq_length=128,\n",
        "               batch_size=32,\n",
        "               learning_rate=2e-5,\n",
        "               num_train_epochs=3,\n",
        "               warmup_proportion=0.1,\n",
        "               save_summary_steps=100,\n",
        "               save_checkpoint_steps=10000,\n",
        "               bert_model_hub=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
        "               output_dir=\"output\"):\n",
        "    label_list = train[label_column].unique().tolist()\n",
        "\n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, max_seq_length, tokenizer, data_column, label_column)\n",
        "    test_features = make_features(test, label_list, max_seq_length, tokenizer, data_column, label_column)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(train_features) / batch_size)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "        bert_model_hub,\n",
        "        output_dir,\n",
        "        save_summary_steps,\n",
        "        save_checkpoint_steps,\n",
        "        label_list,\n",
        "        learning_rate,\n",
        "        num_train_steps,\n",
        "        num_warmup_steps,\n",
        "        batch_size)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    results = []\n",
        "    for epoch in range(num_train_epochs):\n",
        "        estimator.train(input_fn=train_input_fn, steps=steps_per_epoch)\n",
        "\n",
        "        print(\"End of epoch %d.\" %(epoch + 1))\n",
        "\n",
        "        result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "        print(result_dict)\n",
        "        results.append(result_dict)\n",
        "\n",
        "    return results, estimator\n",
        "\n",
        "\n",
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRVzb1Y2y9_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_file):\n",
        "    data = pd.read_csv(data_file)\n",
        "\n",
        "    # Only use the top quartile as polite, and bottom quartile as impolite. Discard the rest.\n",
        "    quantiles = data[\"Normalized Score\"].quantile([0.25, 0.5, 0.75])\n",
        "    # print(quantiles)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        score = data.loc[i, \"Normalized Score\"]\n",
        "        if score <= quantiles[0.25]:\n",
        "            # Bottom quartile (impolite).\n",
        "            data.loc[i, \"Normalized Score\"] = 0\n",
        "        elif score >= quantiles[0.75]:\n",
        "            # Top quartile (polite).\n",
        "            data.loc[i, \"Normalized Score\"] = 1\n",
        "        else:\n",
        "            # Neutral.\n",
        "            data.loc[i, \"Normalized Score\"] = 2\n",
        "\n",
        "    data[\"Normalized Score\"] = data[\"Normalized Score\"].astype(int)\n",
        "\n",
        "    # Discard neutral examples.\n",
        "    data = data[data[\"Normalized Score\"] < 2]\n",
        "    \n",
        "    data.sample(frac=1).reset_index(drop=True)\n",
        "    n_test = len(data) // 10\n",
        "    test_data = data[:n_test]\n",
        "    train_data = data[n_test:]\n",
        "    \n",
        "    print(\"Data loaded successfully. Train=%d, test=%d, total=%d.\" % (len(train_data), len(test_data), len(train_data) + len(test_data)))\n",
        "    print(\"Some train samples:\")\n",
        "    print(train_data.head())\n",
        "    print(\"Some test samples:\")\n",
        "    print(test_data.head())\n",
        "\n",
        "    return train_data, test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BxeqnzOyok3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"Stanford_politeness_corpus.zip\"):\n",
        "  !wget http://www.cs.cornell.edu/~cristian/Politeness_files/Stanford_politeness_corpus.zip\n",
        "\n",
        "if not os.path.exists(\"Stanford_politeness_corpus/wikipedia.annotated.csv\"):\n",
        "  !unzip Stanford_politeness_corpus.zip\n",
        "\n",
        "train_data, test_data = load_data(\"Stanford_politeness_corpus/wikipedia.annotated.csv\")\n",
        "\n",
        "params = {\n",
        "    \"data_column\": \"Request\",\n",
        "    \"label_column\": \"Normalized Score\",\n",
        "    \"batch_size\": 16,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"bert_model_hub\": \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
        "}\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "result, estimator = run_on_dfs(train_data, test_data, **params)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}